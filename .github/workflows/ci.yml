name: Build

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    env:
      CARGO_TERM_COLOR: always
    permissions: {}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      # Speed up apt-get operations by disabling unnecessary man-db auto-update
      - name: Disable man-db auto-update
        run: |
          echo "man-db man-db/auto-update boolean false" | sudo debconf-set-selections
          sudo rm -f /var/lib/man-db/auto-update

      # Install system dependencies for Linux printing
      - name: Install CUPS development libraries
        run: |
          sudo apt-get update
          sudo apt-get install -y libcups2-dev pkg-config clang

      # Setup Rust toolchain for building native library
      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      # Cache Rust dependencies for faster builds
      - uses: Swatinem/rust-cache@v2
        with:
          prefix-key: ${{ runner.os }}-rust

      # Install cargo-llvm-cov for code coverage
      - name: Install cargo-llvm-cov
        uses: taiki-e/install-action@cargo-llvm-cov

      # Install cargo2junit for JUnit XML output from Cargo tests
      - name: Install cargo2junit
        run: cargo install cargo2junit

      # Setup Deno
      - uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x # Run with latest stable Deno.
          cache: true

      # Setup Node.js for N-API module and testing
      - name: Setup Node.js
        uses: actions/setup-node@v5
        with:
          node-version: "20"
          cache: "npm"

      - name: Install NAPI-RS CLI
        run: npm install -g @napi-rs/cli

      # Setup Bun for cross-runtime testing
      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      # Install Task runner
      - name: Setup Task
        uses: arduino/setup-task@v2
        with:
          version: 3.x
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      # Code quality checks (continue on error to gather all results)
      - name: Check Rust formatting
        id: rust-fmt
        run: task fmt:rust:check
        continue-on-error: true

      - name: Run Rust linter (Clippy)
        id: rust-lint
        run: task lint:rust
        continue-on-error: true

      - name: Check TypeScript/JavaScript formatting
        id: prettier-fmt
        run: task fmt:prettier:check
        continue-on-error: true

      # Install Node.js dependencies
      - name: Install Node.js dependencies
        run: npm install

      - name: Run ESLint
        id: eslint
        run: task lint:eslint
        continue-on-error: true

      # Save code quality results for reporting
      - name: Save code quality results
        if: always()
        run: |
          mkdir -p code-quality-results
          echo '{
            "rust_fmt": "${{ steps.rust-fmt.outcome }}",
            "rust_lint": "${{ steps.rust-lint.outcome }}",
            "prettier_fmt": "${{ steps.prettier-fmt.outcome }}",
            "eslint": "${{ steps.eslint.outcome }}"
          }' > code-quality-results/results.json

      - name: Upload code quality results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: code-quality-results
          path: code-quality-results/
          if-no-files-found: ignore

  build-and-test:
    name: Build and Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            name: Linux
          - os: macos-latest
            name: macOS
          - os: windows-latest
            name: Windows
    env:
      PRINTERS_JS_SIMULATE: true # Force simulation mode for all tests
      CARGO_TERM_COLOR: always
    permissions: {}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      # Linux-specific setup
      - name: Disable man-db auto-update and install CUPS libraries (Linux)
        if: runner.os == 'Linux'
        run: |
          echo "man-db man-db/auto-update boolean false" | sudo debconf-set-selections
          sudo rm -f /var/lib/man-db/auto-update
          sudo apt-get update
          sudo apt-get install -y libcups2-dev pkg-config clang

      # Setup Rust toolchain for building native library
      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      # Cache Rust dependencies for faster builds
      - uses: Swatinem/rust-cache@v2
        with:
          prefix-key: ${{ matrix.os }}-rust

      # Install cargo-llvm-cov for code coverage (Linux only)
      - name: Install cargo-llvm-cov (Linux only)
        if: runner.os == 'Linux'
        uses: taiki-e/install-action@cargo-llvm-cov

      # Setup Deno
      - uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x

      # Setup Bun
      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      # Setup Task runner
      - uses: arduino/setup-task@v2
        with:
          version: 3.x
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      # Setup Node.js
      - name: Setup Node
        uses: actions/setup-node@v5
        with:
          node-version: 20

      # Install Node.js dependencies
      - name: Install Node.js dependencies
        run: npm install

      # Build all runtime libraries (includes compilation)
      - name: Build all runtime libraries
        run: task build

      # Run Cargo tests with coverage (Linux only)
      - name: Run Cargo tests with coverage (Linux only)
        if: runner.os == 'Linux'
        id: cargo-tests-coverage
        run: |
          mkdir -p test-results/coverage
          cargo llvm-cov --all-features --workspace --lcov --output-path test-results/coverage/rust.lcov test
        continue-on-error: true

      # Run Cargo tests (all platforms)
      - name: Run Cargo tests
        id: cargo-tests
        shell: bash
        run: |
          mkdir -p test-results
          # Run cargo tests and capture output
          cargo test --all-features --workspace > cargo_test_output.txt 2>&1 || true

      # Generate JUnit report from Cargo test output
      - name: Generate Cargo test JUnit report
        id: cargo-junit
        shell: bash
        run: |

          # Parse the test results from cargo output
          # Look for lines like "test result: ok. 16 passed; 0 failed; 0 ignored"
          RESULT_LINE=$(grep "test result:" cargo_test_output.txt | head -1)

          if [ -n "$RESULT_LINE" ]; then
            echo "Found test result line: $RESULT_LINE"

            # Extract numbers using more robust parsing
            PASSED=$(echo "$RESULT_LINE" | grep -oE "[0-9]+ passed" | grep -oE "[0-9]+" || echo "0")
            FAILED=$(echo "$RESULT_LINE" | grep -oE "[0-9]+ failed" | grep -oE "[0-9]+" || echo "0")
            IGNORED=$(echo "$RESULT_LINE" | grep -oE "[0-9]+ ignored" | grep -oE "[0-9]+" || echo "0")

            # Calculate total tests
            TOTAL=$((PASSED + FAILED + IGNORED))

            echo "Parsed: Total=$TOTAL, Passed=$PASSED, Failed=$FAILED, Ignored=$IGNORED"
          else
            echo "No test result line found, using defaults"
            TOTAL=0
            PASSED=0
            FAILED=0
            IGNORED=0
          fi

          # Generate JUnit XML
          echo '<?xml version="1.0" encoding="UTF-8"?>' > test-results/cargo.xml
          echo '<testsuites>' >> test-results/cargo.xml
          echo "  <testsuite name=\"Rust Cargo Tests\" tests=\"${TOTAL}\" failures=\"${FAILED}\" errors=\"0\" skipped=\"${IGNORED}\">" >> test-results/cargo.xml

          # Add individual test cases from the output
          grep "^test " cargo_test_output.txt | while IFS= read -r line; do
            # Extract test name and status
            TEST_NAME=$(echo "$line" | sed 's/test \(.*\) \.\.\. .*/\1/')
            TEST_STATUS=$(echo "$line" | sed 's/.*\.\.\. \(.*\)/\1/')

            if [ "$TEST_STATUS" = "ok" ]; then
              echo "    <testcase name=\"${TEST_NAME}\" classname=\"cargo\" />" >> test-results/cargo.xml
            elif [ "$TEST_STATUS" = "FAILED" ]; then
              echo "    <testcase name=\"${TEST_NAME}\" classname=\"cargo\">" >> test-results/cargo.xml
              echo "      <failure message=\"Test failed\" />" >> test-results/cargo.xml
              echo "    </testcase>" >> test-results/cargo.xml
            fi
          done

          echo '  </testsuite>' >> test-results/cargo.xml
          echo '</testsuites>' >> test-results/cargo.xml

          echo "Generated JUnit XML with $TOTAL tests"
          cat test-results/cargo.xml
        continue-on-error: true

      # Run comprehensive cross-runtime tests using our TypeScript script
      - name: Run cross-runtime tests
        id: cross-runtime-tests
        run: task test
        continue-on-error: true

      - name: Upload Test Reports
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: test-reports-${{ matrix.name }}
          path: test-results/*.xml
          if-no-files-found: ignore

      - name: Upload Coverage Reports (Linux only)
        if: ${{ always() && runner.os == 'Linux' }}
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: test-results/coverage/*
          if-no-files-found: ignore
